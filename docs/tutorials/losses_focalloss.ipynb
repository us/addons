{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Losses_SigmoidFocalCrossEntropy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/us/addons/blob/master/docs/tutorials/losses_focalloss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "tuOe1ymfHZPu",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        " # TensorFlow Addons Losses: Sigmoid Focal Loss Entropy\n",
        "\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/addons/tutorials/optimizers_lazyadam\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/addons/blob/master/docs/tutorials/optimizers_lazyadam.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/addons/blob/master/docs/tutorials/optimizers_lazyadam.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/addons/docs/tutorials/optimizers_lazyadam.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Overview\n",
        "This notebook will demonstrate how to use the *Sigmoid Focal Loss* function in TensorFlow Addons and compares with *Sparse Categorical Crossentropy Loss* function on **MNIST dataset**.\n",
        "\n",
        "**Resources**:\n",
        "\n",
        "- [Focal Loss for Dense Object Detection (Original Paper)](https://arxiv.org/abs/1708.02002)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bQwBbFVAyHJ_"
      },
      "source": [
        "## Focal Loss\n",
        "\n",
        "Focal loss was first introduced in the [RetinaNet paper](https://arxiv.org/pdf/1708.02002.pdf). Focal loss is extremely useful for classification when you have highly imbalanced classes. It down-weights well-classified examples and focuses on hard examples. The loss value is much high for a sample which is misclassified by the classifier as compared to the loss value corresponding to a well-classified example. One of the best use-cases of focal loss is its usage in object detection where the imbalance between the background class and other classes is extremely high."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxbsgf3d6Bb7",
        "colab_type": "text"
      },
      "source": [
        "# ![probability of ground truth class](https://i.imgur.com/Q2u91zQl.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "42ztALK4ZdyZ",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IqR2PQG4ZaZ0",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ys65MwOLKnXq",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "epochs=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am5rcoxr1Tj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfa.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0_D7CZqkv_Hj"
      },
      "source": [
        "## Prepare the Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U0bS3SyowBoB",
        "colab": {}
      },
      "source": [
        "# Load MNIST dataset as NumPy arrays\n",
        "dataset = {}\n",
        "num_validation = 10000\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(-1, 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(-1, 784).astype('float32') / 255\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10).astype(np.float32)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10).astype(np.float32)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KR01t9v_fxbT"
      },
      "source": [
        "## Build the Model\n",
        "Give a `reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE` because focal loss doesn't mean of losses over sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NxfYhtiSzHf-",
        "colab": {}
      },
      "source": [
        "def create_model(alpha):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(64, input_shape=(784,), activation='relu', name='dense_1'),\n",
        "      tf.keras.layers.Dense(64, activation='relu', name='dense_2'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax', name='predictions'),\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss=tfa.losses.SigmoidFocalCrossEntropy(\n",
        "          alpha=alpha,\n",
        "          reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE\n",
        "          ),\n",
        "      metrics=['accuracy'])\n",
        "\n",
        "  # Train the network\n",
        "  history = model.fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      epochs=epochs)\n",
        "  return history\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HYE-BxhOzFQp"
      },
      "source": [
        "## Train and Evaluate\n",
        "\n",
        "Test Focal loss with different alpha values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO3kJNfvcxJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_0 = create_model(0)\n",
        "history_05 = create_model(0.5)\n",
        "history_1 = create_model(1)\n",
        "history_2 = create_model(2)\n",
        "history_5 = create_model(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnPJFbBWndje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_histories(history, history2, history3, history4, history5, key):\n",
        "  plt.title(key)\n",
        "  plt.plot(history.history[key], label=\"α=0\")\n",
        "  plt.plot(history2.history[key], label=\"α=0.5\")\n",
        "  plt.plot(history3.history[key], label=\"α=1\")\n",
        "  plt.plot(history4.history[key], label=\"α=2\")\n",
        "  plt.plot(history5.history[key], label=\"α=5\")\n",
        "\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel(key)\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "for key in history_0.history.keys():\n",
        "  compare_histories(history_0, history_05, history_1, history_2, history_5, key)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}